{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jupyter-lab/repo/PMGT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import backoff\n",
    "import joblib\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scipy.sparse as sp\n",
    "import timm\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "from pmgt.datasets import (\n",
    "    AmazonReviewImageDataset,\n",
    "    AmazonReviewTextDataset,\n",
    "    text_collate_fn,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "[Amazon Review Datasets](https://nijianmo.github.io/amazon/index.html)\n",
    "- Video Games\n",
    "- Toys and Games\n",
    "- Tools and Home Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P data/VG http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz\n",
    "!wget -P data/TG i://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Toys_and_Games_5.json.gz\n",
    "!wget -P data/THIi http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Tools_and_Home_Improvement_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/VG\"\n",
    "filename = \"Video_Games_5.json.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4c4c73f7ba4619b0b4790f7c8eb289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "497577"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open(os.path.join(data_dir, filename)) as f:\n",
    "    data = [json.loads(l.strip()) for l in tqdm(f)]\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df['reviewDateTime'] = df['unixReviewTime'].map(lambda x: datetime.fromtimestamp(x))\n",
    "df = df.sort_values(by='reviewDateTime')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279333\n",
      "218244\n"
     ]
    }
   ],
   "source": [
    "criterion = datetime(2015, 1, 1, 9)\n",
    "df1 = df[df['reviewDateTime'] < criterion].reset_index(drop=True)\n",
    "df2 = df[df['reviewDateTime'] >= criterion].reset_index(drop=True)\n",
    "print(len(df1))\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root_path = os.path.join(data_dir, \"images\")\n",
    "os.makedirs(image_root_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9704d91b0e6341d194ab79d686241468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8162\n",
      "46731\n",
      "2930\n"
     ]
    }
   ],
   "source": [
    "def _giveup(e):\n",
    "    return str(e) == \"404\"\n",
    "\n",
    "\n",
    "@backoff.on_exception(\n",
    "    backoff.expo,\n",
    "    (requests.exceptions.RequestException, requests.exceptions.ConnectionError),\n",
    "    max_time=30,\n",
    "    max_tries=5,\n",
    "    giveup=_giveup,\n",
    ")\n",
    "def download_image(filepath, image_url):\n",
    "    if os.path.exists(filepath):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        r = requests.get(image_url, stream=True)\n",
    "    except requests.exceptions.MissingSchema:\n",
    "        return False\n",
    "\n",
    "    if r.status_code == 404:\n",
    "        return False\n",
    "    elif r.status_code != 200:\n",
    "        raise requests.exceptions.RequestException(r.status_code)\n",
    "\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        for chunk in r.iter_content(1024):\n",
    "            f.write(chunk)\n",
    "            \n",
    "    return True\n",
    "\n",
    "\n",
    "download_list = []\n",
    "counter = Counter()\n",
    "\n",
    "for index, row in df1[~pd.isna(df1[\"image\"])].iterrows():\n",
    "    for i, image_url in enumerate(row[\"image\"]):\n",
    "        ext = os.path.splitext(image_url)[1]\n",
    "        item_id = row[\"asin\"]\n",
    "        filepath = os.path.join(image_root_path, item_id, f\"{counter[item_id]}{ext}\")\n",
    "        counter[item_id] += 1\n",
    "        download_list.append((filepath, image_url))\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(filepath)):\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "results = Parallel(n_jobs=50, prefer=\"threads\")(\n",
    "    delayed(download_image)(f, u) for f, u in tqdm(download_list)\n",
    ")\n",
    "\n",
    "print(len(download_list))\n",
    "print(len(df1[\"asin\"].unique()))\n",
    "print(len(next(os.walk(image_root_path))[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Visual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"inception_v4\", pretrained=True)\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "dataset = AmazonReviewImageDataset(\n",
    "    image_root_path, transforms=transform, item_ids=df1[\"asin\"].unique()\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=8)\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "visual_feats = []\n",
    "for batch_x in tqdm(dataloader, total=len(dataloader)):\n",
    "    batch_x = batch_x.cuda()\n",
    "    with torch.no_grad():\n",
    "        feat = model.global_pool(model.forward_features(batch_x))\n",
    "        visual_feats.append(feat.cpu())\n",
    "\n",
    "visual_feats = torch.cat(visual_feats)\n",
    "\n",
    "item_visual_feats = []\n",
    "start = 0\n",
    "for num in tqdm(dataset.num_images.values()):\n",
    "    end = start + num\n",
    "    item_visual_feats.append(visual_feats[start:end].mean(dim=0))\n",
    "    start = end\n",
    "item_visual_feats = torch.stack(item_visual_feats).numpy()\n",
    "item_mapping = np.array([item_id for item_id in dataset.num_images.keys()])\n",
    "\n",
    "np.savez(\n",
    "    os.path.join(data_dir, \"visual_feats.npz\"),\n",
    "    feats=item_visual_feats,\n",
    "    mapping=item_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Textual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = (\n",
    "    df1[~pd.isna(df1[\"reviewText\"])]\n",
    "    .groupby(\"asin\")\n",
    "    .apply(lambda r: r[\"reviewText\"].values)\n",
    ")\n",
    "review_text = review_text.to_dict()\n",
    "\n",
    "dataset = AmazonReviewTextDataset(review_text)\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=16,\n",
    "    collate_fn=partial(text_collate_fn, tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "text_feats = []\n",
    "\n",
    "for batch_x in tqdm(dataloader, total=len(dataloader)):\n",
    "    batch_x = {k: v.cuda() for k, v in batch_x.items()}\n",
    "    with torch.no_grad():\n",
    "        text_feats.append(model(**batch_x)[0][:, 0].cpu())\n",
    "\n",
    "text_feats = torch.cat(text_feats)\n",
    "\n",
    "item_textual_feats = []\n",
    "start = 0\n",
    "for num in tqdm(dataset.num_texts.values()):\n",
    "    end = start + num\n",
    "    item_textual_feats.append(text_feats[start:end].mean(dim=0))\n",
    "    start = end\n",
    "item_textual_feats = torch.stack(item_textual_feats).numpy()\n",
    "item_mapping = np.array([item_id for item_id in dataset.num_texts.keys()])\n",
    "\n",
    "np.savez(\n",
    "    os.path.join(data_dir, \"textual_feats.npz\"),\n",
    "    feats=item_textual_feats,\n",
    "    mapping=item_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Product Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c7e84166e34e9f8b240a2e03ad13f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_data = []\n",
    "users_per_item = df1.groupby(by=\"asin\").apply(lambda r: set(r[\"reviewerID\"].unique()))\n",
    "\n",
    "for i in trange(item_ids.shape[0] - 1):\n",
    "    for j in range(i + 1, item_ids.shape[0]):\n",
    "        set1 = users_per_item[item_ids[i]]\n",
    "        set2 = users_per_item[item_ids[j]]\n",
    "        r = len(set1 & set2)\n",
    "        if r >= 3:\n",
    "            graph_data.append((item_ids[i], item_ids[j], r))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(graph_data)\n",
    "\n",
    "for u, v, w in tqdm(G.edges.data(\"weight\")):\n",
    "    w = (np.log(w) + 1) / (np.log(np.sqrt(G.degree[u] * G.degree[v])) + 1)\n",
    "    G.edges[u, v][\"weight\"] = w\n",
    "\n",
    "nx.write_gpickle(G, os.path.join(data_dir, \"graph.gpickle\"))\n",
    "\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Out Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[df2['asin'].isin(G.nodes.keys())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User & Item Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/VG/item_encoder']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_encoder = LabelEncoder().fit(df3['reviewerID'].unique())\n",
    "item_encoder = LabelEncoder().fit(df3['asin'].unique())\n",
    "\n",
    "joblib.dump(user_encoder, os.path.join(data_dir, 'user_encoder'))\n",
    "joblib.dump(item_encoder, os.path.join(data_dir, 'item_encoder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(2022)\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=random_state)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_df.to_json(os.path.join(data_dir, 'train.json'), date_format='iso')\n",
    "test_df.to_json(os.path.join(data_dir, 'test.json'), date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMGT Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 128])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pmgt.pmgt.modeling_pmgt import PMGTModel\n",
    "from pmgt.pmgt.configuration_pmgt import PMGTConfig\n",
    "\n",
    "pmgt_config = PMGTConfig()\n",
    "pmgt = PMGTModel(pmgt_config)\n",
    "\n",
    "feat1 = torch.randn(10, 5, 1536)\n",
    "feat2 = torch.randn(10, 5, 768)\n",
    "\n",
    "hidden_states = pmgt(feat1, feat2)\n",
    "hidden_states[0].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pmgt]",
   "language": "python",
   "name": "conda-env-pmgt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
