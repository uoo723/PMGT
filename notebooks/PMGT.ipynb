{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jupyter-lab/repo/PMGT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import backoff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import timm\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "from pmgt.datasets import (\n",
    "    AmazonReviewImageDataset,\n",
    "    AmazonReviewTextDataset,\n",
    "    text_collate_fn,\n",
    ")\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "[Amazon Review Datasets](https://nijianmo.github.io/amazon/index.html)\n",
    "- Video Games\n",
    "- Toys and Games\n",
    "- Tools and Home Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P data/VG http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz\n",
    "!wget -P data/TG i://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Toys_and_Games_5.json.gz\n",
    "!wget -P data/THIi http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Tools_and_Home_Improvement_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a783b7487d472aa316a9583353b68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "497577"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"./data/VG\"\n",
    "filename = \"Video_Games_5.json.gz\"\n",
    "with gzip.open(os.path.join(data_dir, filename)) as f:\n",
    "    data = [json.loads(l.strip()) for l in tqdm(f)]\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df['reviewDateTime'] = df['unixReviewTime'].map(lambda x: datetime.fromtimestamp(x))\n",
    "df = df.sort_values(by='reviewDateTime')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root_path = os.path.join(data_dir, \"images\")\n",
    "os.makedirs(image_root_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36304e16aef47b78c12cbd3de274af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96514\n",
      "73649\n",
      "21282\n"
     ]
    }
   ],
   "source": [
    "def _giveup(e):\n",
    "    return str(e) == \"404\"\n",
    "\n",
    "\n",
    "@backoff.on_exception(\n",
    "    backoff.expo,\n",
    "    (requests.exceptions.RequestException, requests.exceptions.ConnectionError),\n",
    "    max_time=30,\n",
    "    max_tries=5,\n",
    "    giveup=_giveup,\n",
    ")\n",
    "def download_image(filepath, image_url):\n",
    "    if os.path.exists(filepath):\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        r = requests.get(image_url, stream=True)\n",
    "    except requests.exceptions.MissingSchema:\n",
    "        return\n",
    "\n",
    "    if r.status_code == 404:\n",
    "        return\n",
    "    elif r.status_code != 200:\n",
    "        raise requests.exceptions.RequestException(r.status_code)\n",
    "\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        for chunk in r.iter_content(1024):\n",
    "            f.write(chunk)\n",
    "\n",
    "\n",
    "download_list = []\n",
    "counter = Counter()\n",
    "\n",
    "for index, row in df[~pd.isna(df[\"image\"])].iterrows():\n",
    "    for i, image_url in enumerate(row[\"image\"]):\n",
    "        ext = os.path.splitext(image_url)[1]\n",
    "        item_id = row[\"asin\"]\n",
    "        filepath = os.path.join(image_root_path, item_id, f\"{counter[item_id]}{ext}\")\n",
    "        counter[item_id] += 1\n",
    "        download_list.append((filepath, image_url))\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(filepath)):\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "Parallel(n_jobs=50, prefer=\"threads\")(\n",
    "    delayed(download_image)(f, u) for f, u in tqdm(download_list)\n",
    ")\n",
    "\n",
    "print(len(download_list))\n",
    "print(len(df[\"asin\"].unique()))\n",
    "print(len(next(os.walk(image_root_path))[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279333\n",
      "218244\n"
     ]
    }
   ],
   "source": [
    "criterion = datetime(2015, 1, 1, 9)\n",
    "df1 = df[df['reviewDateTime'] < criterion]\n",
    "df2 = df[df['reviewDateTime'] >= criterion]\n",
    "print(len(df1))\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Visual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e54ddc73ac45d68b5653134c4aeaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe2fafcd09d412ba29d8467a769290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = timm.create_model(\"inception_v4\", pretrained=True)\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "dataset = AmazonReviewImageDataset(\n",
    "    image_root_path, transforms=transform, item_ids=df1[\"asin\"].unique()\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=8)\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "visual_feats = []\n",
    "for batch_x in tqdm(dataloader, total=len(dataloader)):\n",
    "    batch_x = batch_x.cuda()\n",
    "    with torch.no_grad():\n",
    "        feat = model.global_pool(model.forward_features(batch_x))\n",
    "        visual_feats.append(feat.cpu())\n",
    "\n",
    "visual_feats = torch.cat(visual_feats)\n",
    "\n",
    "item_visual_feats = []\n",
    "start = 0\n",
    "for num in tqdm(dataset.num_images.values()):\n",
    "    end = start + num\n",
    "    item_visual_feats.append(visual_feats[start:end].mean(dim=0))\n",
    "    start = end\n",
    "item_visual_feats = torch.stack(item_visual_feats).numpy()\n",
    "item_mapping = np.array([item_id for item_id in dataset.num_images.keys()])\n",
    "\n",
    "np.savez(\n",
    "    os.path.join(data_dir, \"visual_feats.npz\"),\n",
    "    feats=item_visual_feats,\n",
    "    mapping=item_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Textual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d61c99580c340d28f88d73e5d2fa91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4365 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890653cbb5d54482b2232232468523e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14507 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_text = (\n",
    "    df1[~pd.isna(df1[\"reviewText\"])]\n",
    "    .groupby(\"asin\")\n",
    "    .apply(lambda r: r[\"reviewText\"].values)\n",
    ")\n",
    "review_text = review_text.to_dict()\n",
    "\n",
    "dataset = AmazonReviewTextDataset(review_text)\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=16,\n",
    "    collate_fn=partial(text_collate_fn, tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "text_feats = []\n",
    "\n",
    "for batch_x in tqdm(dataloader, total=len(dataloader)):\n",
    "    batch_x = {k: v.cuda() for k, v in batch_x.items()}\n",
    "    with torch.no_grad():\n",
    "        text_feats.append(model(**batch_x)[0][:, 0].cpu())\n",
    "\n",
    "text_feats = torch.cat(text_feats)\n",
    "\n",
    "item_textual_feats = []\n",
    "start = 0\n",
    "for num in tqdm(dataset.num_texts.values()):\n",
    "    end = start + num\n",
    "    item_textual_feats.append(text_feats[start:end].mean(dim=0))\n",
    "    start = end\n",
    "item_textual_feats = torch.stack(item_textual_feats).numpy()\n",
    "item_mapping = np.array([item_id for item_id in dataset.num_texts.keys()])\n",
    "\n",
    "np.savez(\n",
    "    os.path.join(data_dir, \"textual_feats.npz\"),\n",
    "    feats=item_textual_feats,\n",
    "    mapping=item_mapping,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pmgt]",
   "language": "python",
   "name": "conda-env-pmgt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
